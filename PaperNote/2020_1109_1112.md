# Paper Weekly

> 2020/11/2-11/05

|Index|Area|Title & Source|Idea|
|:---:|:--|:-------------|:---|
|1|End-to-End Retrieval|Dc-bert: Decoupling question and document for efficient contextual encoding. *Nie, Ping and Zhang, Yuyu and Geng, Xiubo and Ramamurthy, Arun and Song, Le and Jiang, Daxin.* SIGIR 2020. [[paper]](https://arxiv.org/pdf/2002.12591.pdf)|针对BERT-Reranker需要concate Q+D Interaction速度慢的问题 (难以并行interact 多个Queries与大量docs)；提出Dual-BERT: (1) online BERT encode Q, (2) offline BERT encode docs (3) a transformer layer interact encode (Q + D) (4) binary classification|
|2|Rerank Effectiveness|**Efficient Document Re-Ranking for Transformers by Precomputing Term Representations.** *MacAvaney, Sean and Nardini, Franco Maria and Perego, Raffaele and Tonellotto, Nicola and Goharian, Nazli and Frieder, Ophir.* arXiv 2020. [[paper]](https://arxiv.org/pdf/2004.14255.pdf)|**提出:** (1)将doc term representations precomputed and stored in the index stage, 然后在query time在计算query term and doc term inertaction top-layers of transformer实现speedup; 由于需要store doc term representations，提出在最后几层transformer layer前先用an extra layer (feed-forward & normalized) 对term vectors进行压缩，然后，optimize该compress network的目标为reduce the mean squared error of the attention score between added transformer layers and previous transformer layers.|
|3|BERT Analysis|**What does BERT look at? An Analysis of BERT’s Attention.** *Clark, Kevin and Khandelwal, Urvashi and Levy, Omer and Manning, Christopher D.* ACL 2019. [[paper]](https://www.aclweb.org/anthology/W19-48.pdf#page=290)|
|4|Pairwise softmax loss|**Neural Ranking Models with Weak Supervision.** *Dehghani, Mostafa and Zamani, Hamed and Severyn, Aliaksei and Kamps, Jaap and Croft, W Bruce.* SIGIR 2017. [[paper]](https://dl.acm.org/doi/pdf/10.1145/3077136.3080832)|
||
||Variational Autoencoder|OPTIMUS: Organizing Sentences via Pre-trained Modeling of a Latent Space. [[paper]](https://arxiv.org/pdf/2004.04092.pdf)|
||Doc expansion|Document expansion by query prediction. *Rodrigo Nogueira, Wei Yang, Jimmy Lin, Kyunghyun Cho.* arXiv 2019. [[paper]](https://arxiv.org/pdf/1904.08375.pdf)
||Doc expansion|From doc2query to docTTTTTquery. *Nogueira, Rodrigo and Lin, Jimmy and Epistemic, AI.* arXiv 2019. [[paper]](https://cs.uwaterloo.ca/~jimmylin/publications/Nogueira_Lin_2019_docTTTTTquery.pdf)|
||Rank fusion|Reciprocal rank fusion outperforms condorcet and individual rank learning methods. *Cormack, Gordon V and Clarke, Charles LA and Buettcher, Stefan.* SIGIR 2009. [[paper]](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)|
