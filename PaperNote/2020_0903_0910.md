# Paper Weekly

> 2020/9/3-9/10

|Index|Area|Source|Title|Idea|
|:---:|:---------:|:--|:---|:----|
|1|Data Subsampling|AAAI 2020|Less Is Better: Unweighted Data Subsampling via Influence Function [~Paper](https://arxiv.org/pdf/1912.01321.pdf)|**What:** 在Big Data上训练complex model是很困难的，本文提出了一种data subsampling的方法旨在利用subset data达到超越full set的效果. **How:** 利用Influence function来获得each training point对entire test loss的影响 (weight)，然后根据此影响对training set进行采样|
|2|Data Subsampling|NeurIPS 2019|Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting [~Paper](https://arxiv.org/pdf/1902.07379.pdf)|针对DNN容易overfit corrupted labels & class imbalance in training data，提出了一种adaptively reweight的方法，根据training loss and dev loss来优化生成weight的small Meta weight net (MLP)|
|3|Meta Learning|ICML 2017|Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks [~Paper](https://arxiv.org/pdf/1703.03400.pdf)|
|4|Data Manipulation|NeurIPS 2019|Learning Data Manipulation for Augmentation and Weighting [~Paper](https://arxiv.org/pdf/1910.12795.pdf)|
|%|Meta-Learning|arXiv 2020|Yet Meta Learning Can Adapt Fast, It Can Also Break Easily [~Paper](https://arxiv.org/pdf/2009.01672.pdf)|
