# Paper Weekly

> 2020/10/8-10/15

|Index|Area|Title & Source|Idea|
|:---:|:--|:-------------|:---|
|1|Doc Ranking|ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. *SIGIR 2020.* [[Paper]](https://arxiv.org/pdf/2004.12832.pdf)|鉴于employ BERT in doc ranking时query与doc的all-to-all interaction的昂贵的计算代价，本文提出了只在最后一层对query与doc进行interation. 具体做法为: 先用BERT对query与doc单独进行encode,然后最后使用MaxSum来聚合query与doc的similarity. 实验证明这种方法可以在保证ranking performance的前提下，大幅减少计算量。|
|2|Dimensionality Reduction|Dimensionality Reduction by Learning an Invariant Mapping. *CVPR 2006.*[[Paper]](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)|看到第2页了, 继续阅读|
|3|Dense Retrieval|Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval. *ArXiv 2020.* [[Paper]](https://arxiv.org/pdf/2007.00808.pdf)|**Motivation.** 现有的Dense Retrieval只能与sparse retrieval融合才能发挥比较好性能，本文认为这是由于DR在training过程中使用的negative与testing的negative之间存在discrepancy. 常见的选取negative的方法有：BM25 & Rand. **Proposed.** 本文提出以一种可以resolve the gap的方法，它在训练过程中，从DR实际inference出的top结果中选取negatives.|
|4|IR dataset|MS MARCO: A Human Generated MAchine Reading COmprehension Dataset. *ICLR 2017.* [[Paper]](https://openreview.net/pdf?id=Hk1iOLcle)|详细看了一下MS MARCO构建的Document Ranking dataset的过程. (1) 把所有corpora切成passage pool (2) 然后用BM25抽回1000 docs (3) 让human去标注相关性label (1为相关)，没有标注相关的即为不相关。但注意不是所有1000 docs都会被human seen, 因此可能存在被标为0的doc比标为1的doc更相关|
