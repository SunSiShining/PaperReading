# Paper Weekly

> 2020/11/2-11/05

|Index|Area|Title & Source|Idea|
|:---:|:--|:-------------|:---|
|1|Dense retrieval|Learning To Retrieve: How to Train a Dense Retrieval Model Effectively and Efficiently. [[paper]](https://arxiv.org/pdf/2010.10469.pdf)|**针对问题**：现有dense retrieval依赖从corpus中负采样，但是learn to rerank samples与learn to retrieve from the entire corpus是存在偏差的，且训练效率低. **本文提出**：fix document representations (训好了)，只学习将user query投射到doc space中，使得query vector更接近于relevant docs原理irrelevant docs. **实验效果**：声称性能超越了SOTA retriever, 并且达到170x speed-up.|
|2|Variational Autoencoder|OPTIMUS: Organizing Sentences via Pre-trained Modeling of a Latent Space. [[paper]](https://arxiv.org/pdf/2004.04092.pdf)|
|3|Doc expansion|Document expansion by query prediction. *Rodrigo Nogueira, Wei Yang, Jimmy Lin, Kyunghyun Cho.* arXiv 2019. [[paper]](https://arxiv.org/pdf/1904.08375.pdf)
|4|Doc expansion|From doc2query to docTTTTTquery. *Nogueira, Rodrigo and Lin, Jimmy and Epistemic, AI.* arXiv 2019. [[paper]](https://cs.uwaterloo.ca/~jimmylin/publications/Nogueira_Lin_2019_docTTTTTquery.pdf)|
|5|End-to-End Retrieval|Dc-bert: Decoupling question and document for efficient contextual encoding. *Nie, Ping and Zhang, Yuyu and Geng, Xiubo and Ramamurthy, Arun and Song, Le and Jiang, Daxin.* SIGIR 2020. [[paper]](https://arxiv.org/pdf/2002.12591.pdf)
|6|End-to-End Retrieval|Efficient document re-ranking for transformers by precomputing term representations. *MacAvaney, Sean and Nardini, Franco Maria and Perego, Raffaele and Tonellotto, Nicola and Goharian, Nazli and Frieder, Ophir.* arXiv 2020. [[paper]](https://arxiv.org/pdf/2004.14255.pdf)|
|7|Dense retrieval|Neural Passage Retrieval with Improved Negative Contrast. *Lu, Jing and Abrego, Gustavo Hernandez and Ma, Ji and Ni, Jianmo and Yang, Yinfei.* arXiv 2020. [[paper]](https://arxiv.org/pdf/2010.12523.pdf)|使用QG pretraining dense retrieval + fine-tuning. 测试了4种不同的negative sampling方法: (1) low-dim model top@k (2) high-dim model top@k (3) BM25 retrieved top@k (4) 用同一篇doc的other passages|
|8|Rank fusion|Reciprocal rank fusion outperforms condorcet and individual rank learning methods. *Cormack, Gordon V and Clarke, Charles LA and Buettcher, Stefan.* SIGIR 2009. [[paper]](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)|
