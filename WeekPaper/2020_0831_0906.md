# Paper Weekly

> 2020/8/31-9/6

- **Understanding black-box predictions via influence functions** <a href="#1-Understanding">~About</a>  **Ù©(à¹‘>â—¡<à¹‘)Û¶â¤ Best Recommend â¤**
- **ORCAS: 18 Million Clicked Query-Document Pairs for Analyzing Search** <a href="#2-ORCAS">~About</a>
- **Dense Passage Retrieval for Open-Domain Question Answering** [~Paper](https://arxiv.org/pdf/2004.04906.pdf)
- **Complementing Lexical Retrieval with Semantic Residual Embedding** [~Paper](https://arxiv.org/pdf/2004.13969.pdf)


## [2. ORCAS](#contents)

**ORCAS: 18 Million Clicked Query-Document Pairs for Analyzing Search** [~Paper](https://arxiv.org/pdf/1703.04730.pdf)

æœ¬æ–‡å‘å¸ƒäº†ä¸€ä¸ªpublicçš„click logs datasetï¼Œä¸TREC Deep Learning Track ç›¸å…³ã€‚æ–‡ä¸­æœ‰ä¸ªä¾‹å­æŒºæœ‰æ„æ€ï¼Œquery Pandaså¯ä»¥linkåˆ°å¾ˆå¤šç›¸å…³topic: ç†ŠçŒ«ã€æ­Œæ›²ç­‰ç­‰ï¼Œå¦‚ä½•ç¡®å®šmost query-realted docsï¼Œä½¿ç”¨user clickå°±å‘ç°æ¾³æ´²çš„ç½‘ç»œæ›´å¯èƒ½linkåˆ°"ç†ŠçŒ«æ±‚åŠ©çƒ­çº¿"ï¼Œä½†æ˜¯ç¾å›½ç½‘é¡µå°±ä¸æ˜¯ã€‚ä½†æ˜¯ä»…å­˜çš„å¼€æºuser click datasetéƒ½æ˜¯IDåŒ¿ååŒ–çš„ï¼Œå®ƒå°±æ²¡æ³•æä¾›æä¾›è¿™æ–¹é¢çš„ä¿¡æ¯ï¼Œä½†æ˜¯æ­¤paper releaseçš„Open Resource for Click Analysis in Search (ORCAS)ï¼Œä¸ä»…å¯ä»¥æä¾› user-level or session-level informationï¼Œè¿˜å¯ä»¥release without privacy violation.

ä½†æ˜¯æœ¬æ–‡åˆ©ç”¨ORCAS +  TREC DL dataå…±åŒtrain rankerç«Ÿç„¶no statistically significant gains. Possible Future work: Correctly weighting and adjusting the data to achieve a significant gain on a test set of 43 queries is left as future work.


## [1. Understanding]

**Understanding black-box predictions via influence functions** [~Paper](https://arxiv.org/pdf/1703.04730.pdf)

### >> Abstract

å¦‚ä½•è§£é‡Š a black-box modelçš„predictionï¼Ÿæœ¬æ–‡é‡‡ç”¨influence functionsï¼Œè¿½è¸ªmodel prediction to training data, æœ€ç»ˆç¡®å®šåˆ°åº•å“ªä¸ªdataå¯¹model preidictionè‡³å…³é‡è¦ã€‚

ä¸ºäº†å¯¹machine learningçš„settingè¿ç”¨influence functions, æœ¬æ–‡æå‡ºä¸€ç§æ–¹æ³•ä»…éœ€access to gradients and Hessian-vector products.

å³ä½¿åœ¨non-convex and non-differentiable modelä¸Šï¼Œinfluence functionsä»æä¾›äº†æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚

æœ¬æ–‡åœ¨Linear model and Convolution neural networkä¸ŠéªŒè¯äº†influence functionså¯ä»¥ç”¨äºï¼š
- Understanding model behavior
- debugging model
- detecting model behavior
- create visually-indistinguishable training-set attacks

ğŸ¤” æ‰€ä»¥ä»€ä¹ˆæ˜¯influence functions? å®ƒåˆæ˜¯å¦‚ä½•åˆ©ç”¨gradientsæ¥trac model predictionsçš„ï¼Ÿå¥½å¥‡ä½œè€…æ€ä¹ˆåœ¨modelä¸ŠéªŒè¯æåˆ°çš„å‡ ç§ç”¨é€”ï¼Ÿ

### >> Introduction

åœ¨è§£é‡Šblack-box modelä¸Šå·²æœ‰çš„å·¥ä½œå¤§å¤šç ”ç©¶: ä¸€ä¸ªå›ºå®šçš„modelï¼Œå¦‚ä½•åšå‡ºç‰¹å®šçš„é¢„æµ‹, æ¯”å¦‚å¯¹test pointè¿›è¡Œæ‰°åŠ¨ï¼Œçœ‹çœ‹predictionå¦‚ä½•å˜åŒ–ã€‚æœ¬æ–‡é€šè¿‡modelçš„learning algorithmè¿½è¸ªmodel predictionæœ€ç»ˆback to its training data.

ä¸ºäº†åˆ¤æ–­a training pointå¯¹a predictionçš„å½±å“ï¼Œæˆ‘ä»¬å¯ä»¥é—®è¿™ä¹ˆä¸€ä¸ªé—®é¢˜: å¦‚æœæ²¡æœ‰è¿™ä¸ªtraining pointä¼šæ€ä¹ˆæ ·? ä½†æ˜¯å¦‚æœä¸ºäº†æµ‹è¯•a training dataå°±é‡æ–°è®­ä¸€émodelè¿™ä»£ä»·ä¹Ÿå¤ªå¤§äº†ï¼Œå› æ­¤ä½œè€…ä½¿ç”¨äº†influence functions (a classic technique from robust statistics, 1980)ï¼Œå®ƒå‘Šè¯‰äº†æˆ‘ä»¬å¦‚æœå¯¹a training pointè¿›è¡Œæ— ç©·å°çš„upweightï¼Œmodel parameterå¦‚ä½•å˜åŒ–ã€‚

ä½†influence functionçš„åº”ç”¨éšœç¢æ˜¯: expensive second derivative calculations and assume model differentiability and convexity.

æˆ‘ä»¬å¯ä»¥åˆ©ç”¨second-order optimzation æŠ€æœ¯å¯¹influence functionsè¿›è¡Œè¿›è¡Œï¼Œå³ä½¿åœ¨ä¸å¯å¾®æˆ–éå‡¸é—®é¢˜ä¸Šéƒ½å…·å¤‡accurate.

### >> Approach

é¦–å…ˆä»‹ç»äº†previous influence functionæ˜¯æ€ä¹ˆåšçš„ï¼šupweight training point, evaluate on test setï¼Œç„¶ååœ¨2.1èŠ‚è¿›è¡Œå»¶æ‹“æˆå¯¹training pointè¿›è¡ŒPerturbing
