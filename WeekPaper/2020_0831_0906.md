# Paper Weekly

> 2020/8/31-9/6

- **Understanding black-box predictions via influence functions** <a href="#1-Understanding">~About</a>  **٩(๑>◡<๑)۶❤ Best Recommend ❤**
- **ORCAS: 18 Million Clicked Query-Document Pairs for Analyzing Search** <a href="#2-ORCAS">~About</a>
- **Dense Passage Retrieval for Open-Domain Question Answering** [~Paper](https://arxiv.org/pdf/2004.04906.pdf)
- **Complementing Lexical Retrieval with Semantic Residual Embedding** [~Paper](https://arxiv.org/pdf/2004.13969.pdf)


## [2. ORCAS](#contents)

**ORCAS: 18 Million Clicked Query-Document Pairs for Analyzing Search** [~Paper](https://arxiv.org/pdf/1703.04730.pdf)

本文发布了一个public的click logs dataset，与TREC Deep Learning Track 相关。文中有个例子挺有意思，query Pandas可以link到很多相关topic: 熊猫、歌曲等等，如何确定most query-realted docs，使用user click就发现澳洲的网络更可能link到"熊猫求助热线"，但是美国网页就不是。但是仅存的开源user click dataset都是ID匿名化的，它就没法提供提供这方面的信息，但是此paper release的Open Resource for Click Analysis in Search (ORCAS)，不仅可以提供 user-level or session-level information，还可以release without privacy violation.

但是本文利用ORCAS +  TREC DL data共同train ranker竟然no statistically significant gains. Possible Future work: Correctly weighting and adjusting the data to achieve a significant gain on a test set of 43 queries is left as future work.


## [1. Understanding]

**Understanding black-box predictions via influence functions** [~Paper](https://arxiv.org/pdf/1703.04730.pdf)

### >> Abstract

如何解释 a black-box model的prediction？本文采用influence functions，追踪model prediction to training data, 最终确定到底哪个data对model preidiction至关重要。

为了对machine learning的setting运用influence functions, 本文提出一种方法仅需access to gradients and Hessian-vector products.

即使在non-convex and non-differentiable model上，influence functions仍提供了有价值的信息。

本文在Linear model and Convolution neural network上验证了influence functions可以用于：
- Understanding model behavior
- debugging model
- detecting model behavior
- create visually-indistinguishable training-set attacks

🤔 所以什么是influence functions? 它又是如何利用gradients来trac model predictions的？好奇作者怎么在model上验证提到的几种用途？

### >> Introduction

在解释black-box model上已有的工作大多研究: 一个固定的model，如何做出特定的预测, 比如对test point进行扰动，看看prediction如何变化。本文通过model的learning algorithm追踪model prediction最终back to its training data.

为了判断a training point对a prediction的影响，我们可以问这么一个问题: 如果没有这个training point会怎么样? 但是如果为了测试a training data就重新训一遍model这代价也太大了，因此作者使用了influence functions (a classic technique from robust statistics, 1980)，它告诉了我们如果对a training point进行无穷小的upweight，model parameter如何变化。

但influence function的应用障碍是: expensive second derivative calculations and assume model differentiability and convexity.

我们可以利用second-order optimzation 技术对influence functions进行进行，即使在不可微或非凸问题上都具备accurate.

### >> Approach

首先介绍了previous influence function是怎么做的：upweight training point, evaluate on test set，然后在2.1节进行延拓成对training point进行Perturbing
