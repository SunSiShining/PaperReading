# [ACL 2020](https://www.aclweb.org/anthology/events/acl-2020/)

1.
äººç±»ç”Ÿæˆçš„IRæ•°æ® -> äººè¿›è¡Œè´¨é‡è¯„ä¼°
æ¨¡å‹åˆæˆçš„IRæ•°æ® -> å¦‚ä½•è¿›è¡Œè´¨é‡è¯„ä¼°ï¼Ÿ influencial function

2.
ä¸€ç¯‡æ–‡æ¡£å¯ä»¥å› ä¸ºä¸åŒcontentè¢«å¤šä¸ªqueriesæ ‡è®°ä¸ºç›¸å…³, BERTScoreç”¨äºè‡ªåŠ¨æµ‹è¯„text generation
è¿™æœ‰ç‚¹ç±»ä¼¼äºdiverse caption generation (https://arxiv.org/pdf/1703.06029.pdf; https://arxiv.org/pdf/1606.07770.pdf)



|Tag|Title|Link|Note|
|:---|:---|:----|:---|
|å…ƒå­¦ä¹ |Learning Low-Resource End-To-End Goal-Oriented Dialog for Fast and Reliable System Deployment|https://www.aclweb.org/anthology/2020.acl-main.57/ |multi-domain dialogï¼Œæ‰€ä»¥å¯ä»¥åˆ©ç”¨MAMLè¿›è¡Œadaption|
|å¯¹æŠ—è®­ç»ƒ|Neural Topic Modeling with Bidirectional Adversarial Training|https://www.aclweb.org/anthology/2020.acl-main.32/| ç§‘æ™®äº†ä¸€ä¸‹å˜åˆ†è‡ªç¼–ç å™¨ï¼Œè®©æˆ‘æƒ³åˆ°äº†æ€æ ·çš„ç”Ÿæˆæ•°æ®æ‰æ˜¯å¥½çš„|
|è¯„ä¼°æ–¹æ³•|Improving Image Captioning Evaluation by Considering Inter References Variance|https://www.aclweb.org/anthology/2020.acl-main.93/|
||
|ä¸è¿ç§»å­¦ä¹ ç›¸å…³çš„æ•°æ®ç”Ÿæˆ|Review-based Question Generation with Adaptive Instance Transfer and Augmentation|https://www.aclweb.org/anthology/2020.acl-main.26/ |å¯ä»¥æŠŠQGå½“åšæ˜¯dual task (æœ‰ç›¸å…³paper)|
|Zero-shot åˆæˆæ•°æ®|Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking|https://www.aclweb.org/anthology/2020.acl-main.12/ |åˆ©ç”¨å¤§é‡æ•°æ® + å°è§„æ¨¡target templeteåšç”Ÿæˆ|
|å°†question generationä½œä¸ºæ— ç›‘ç£æ¨¡æ‹Ÿé€€ç«|Unsupervised Paraphrasing by Simulated Annealing|https://www.aclweb.org/anthology/2020.acl-main.28/ |æ ¹æ®seed queriesæ¥è¿­ä»£å‡ºä¸åŒçš„queries|
|å…ƒå­¦ä¹ ï¼Œå°æ ·æœ¬|Dynamic Memory Induction Networks for Few-Shot Text Classification|https://www.aclweb.org/anthology/2020.acl-main.102/ |short paperï¼Œæ„Ÿè§‰æœ‰ç‚¹ç”¨å¤„ï¼Œä½†æ˜¯ä¸€ä¸‹å­æ²¡çœ‹æ‡‚|
|é«˜æ•ˆç‡çš„å¤§è§„æ¨¡æ£€ç´¢|Generative Semantic Hashing Enhanced via Boltzmann Machines|https://www.aclweb.org/anthology/2020.acl-main.71/ |æ¶‰åŠçš„çŸ¥è¯†ç‚¹æ¯”è¾ƒå¤šï¼Œçœ‹ä¸å¤ªæ‡‚ï¼Œä½†æ˜¯å¦‚æœè€ƒè™‘åšdense retrievalçš„è¯å¯ä»¥è€ƒè™‘å†çœ‹çœ‹|
|è¯„ä¼°æ–¹æ³•|Multi-Hypothesis Machine Translation Evaluation|https://www.aclweb.org/anthology/2020.acl-main.113/|




|Tag|Title|Link|Note|
|:---|:---|:----|:---|
|å¯è§£é‡Šæ€§è¯„ä¼°æ–¹æ³•|Evaluating Explanation Methods for Neural Machine Translation|https://www.aclweb.org/anthology/2020.acl-main.35/|
|å¦‚ä½•è¯„ä¼°ç”Ÿæˆçš„å¼±ç›‘ç£æ•°æ®ï¼Ÿ|Designing Precise and Robust Dialogue Response Evaluators|https://www.aclweb.org/anthology/2020.acl-main.4|çŸ­æ–‡åˆ›æ–°ä¸å¤§|
|æ›´å¥½çš„è¯„ä¼°æ–¹æ³•|Evaluating Dialogue Generation Systems via Response Selection|https://www.aclweb.org/anthology/2020.acl-main.55/|
|è¯„ä¼°æ–¹æ³•|Interactive Construction of User-Centric Dictionary for Text Analytics|https://www.aclweb.org/anthology/2020.acl-main.72/|
|è¯„ä¼°æ–¹æ³•|Multimodal Quality Estimation for Machine Translation|https://www.aclweb.org/anthology/2020.acl-main.114/|
|ğŸ˜|
|åŸºäºå¤–éƒ¨çŸ¥è¯†ç”Ÿæˆæ•°æ®ï¼Ÿ|Generating Informative Conversational Response using Recurrent Knowledge-Interaction and Knowledge-Copy|https://www.aclweb.org/anthology/2020.acl-main.6/|
|éå›å½’æ–‡æœ¬ç”Ÿæˆ|A Study of Non-autoregressive Model for Sequence Generation|https://www.aclweb.org/anthology/2020.acl-main.15/ | Designäº†ä¸€å¥—åˆ†ææ–¹æ³•åˆ†æäº†éè‡ªå›å½’å’Œè‡ªå›å½’æ–¹æ³•çš„åŒºåˆ«|
|é’ˆå¯¹ç°æœ‰ç”Ÿæˆæ•°æ®çš„ç¼ºé™·|Fluent Response Generation for Conversational Question Answering|https://www.aclweb.org/anthology/2020.acl-main.19/|
|å¦‚ä½•ç”ŸæˆIRæ•°æ®|Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs|https://www.aclweb.org/anthology/2020.acl-main.20/|
|å¦‚ä½•ç”ŸæˆIRæ•°æ®|Learning to Ask More: Semi-Autoregressive Sequential Question Generation under Dual-Graph Interaction|https://www.aclweb.org/anthology/2020.acl-main.21/|
|å¦‚ä½•ç”ŸæˆIRæ•°æ®|Contextualized Weak Supervision for Text Classification|https://www.aclweb.org/anthology/2020.acl-main.30/|
|GNNåˆ©ç”¨å•ç¯‡æ–‡æ¡£ç”ŸæˆæŸ¥è¯¢ï¼Œæˆ–è€…åˆ©ç”¨å¤šç¯‡æ–‡æ¡£ç”ŸæˆæŸ¥è¯¢|Every Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks|https://www.aclweb.org/anthology/2020.acl-main.31/|
|ç”Ÿæˆå¼±ç›‘ç£IRæ•°æ®|A Methodology for Creating Question Answering Corpora Using Inverse Data Annotation|https://www.aclweb.org/anthology/2020.acl-main.84/|
|æ›´å¥½çš„ç”Ÿæˆæ•°æ®|Improving Truthfulness of Headline Generation|https://www.aclweb.org/anthology/2020.acl-main.123/|
|Query Generation Graph, KBQA|Query Graph Generation for Answering Multi-hop Complex Questions from Knowledge Bases|https://www.aclweb.org/anthology/2020.acl-main.91/|
|ğŸ˜|
|å°†æ•°æ®ç”Ÿæˆçœ‹åšå¦ä¸€ä¸ªä»»åŠ¡ï¼Ÿ|Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained Conversational Representations|https://www.aclweb.org/anthology/2020.acl-main.11/|
|æå‡ºæ–°ä»»åŠ¡|Few-Shot NLG with Pre-Trained Language Model|https://www.aclweb.org/anthology/2020.acl-main.18/|
|æ–°äº‹ç‰©ï¼šcode-switching patterns|Code-Switching Patterns Can Be an Effective Route to Improve Performance of Downstream NLP Applications: A Case Study of Humour, Sarcasm and Hate Speech Detection|https://www.aclweb.org/anthology/2020.acl-main.96/|
|æ–°ä»»åŠ¡|Expertise Style Transfer: A New Task Towards Better Communication between Experts and Laymen|https://www.aclweb.org/anthology/2020.acl-main.100/|
|NLUï¼Œæ–°ä»»åŠ¡|PuzzLing Machines: A Challenge on Learning From Small Data|https://www.aclweb.org/anthology/2020.acl-main.115/|
|ğŸ˜|
|Graph to sequence|Line Graph Enhanced AMR-to-Text Generation with Mix-Order Graph Attention Networks|https://www.aclweb.org/anthology/2020.acl-main.67/|
|æ¯”è¾ƒå·§å¦™çš„å°æ€è·¯|Text Classification with Negative Supervision|https://www.aclweb.org/anthology/2020.acl-main.33/|
|å¾ˆç¥å¥‡çš„ç†è®º|A Three-Parameter Rank-Frequency Relation in Natural Languages|https://www.aclweb.org/anthology/2020.acl-main.44/|
|ğŸ˜|
|é•¿æ–‡æœ¬|Location Attention for Extrapolation to Longer Sequences|https://www.aclweb.org/anthology/2020.acl-main.39/|
|æå‡IR modelçš„è®­ç»ƒæ•ˆç‡|Norm-Based Curriculum Learning for Neural Machine Translation|https://www.aclweb.org/anthology/2020.acl-main.41/|
|çŸ­æ–‡æœ¬æŠ½å–|GCAN: Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media|https://www.aclweb.org/anthology/2020.acl-main.48/|
|ğŸ˜|
|æ•°å­¦ä¼˜åŒ–|Improved Natural Language Generation via Loss Truncation|https://www.aclweb.org/anthology/2020.acl-main.66/|
|ğŸ˜|
|IRé‡Œé¢æœ‰ç±»ä¼¼data imbalanceé—®é¢˜å—|Dice Loss for Data-imbalanced NLP Tasks|https://www.aclweb.org/anthology/2020.acl-main.45/|
|FAQ Retrieval|Unsupervised FAQ Retrieval with Question Generation and BERT|https://www.aclweb.org/anthology/2020.acl-main.74/|
|ğŸ˜ç»“åˆç”¨æˆ·å†å²ä¿¡æ¯è¿›è¡Œæ–°é—»æ¨è|Fine-grained Interest Matching for Neural News Recommendation|https://www.aclweb.org/anthology/2020.acl-main.77/|
|ğŸ˜åˆ©ç”¨influencial functionè§£é‡ŠGNN-based modelå¯¹social mediaä¸­user åœ°ç†ä½ç½®çš„é¢„æµ‹|Interpreting Twitter User Geolocation|https://www.aclweb.org/anthology/2020.acl-main.79/|
|ğŸ˜|
|æ–°æ•°æ®é›†|The TechQA Dataset|https://www.aclweb.org/anthology/2020.acl-main.117/|
|å¯åˆ©ç”¨çš„æ•°æ®é›†|A Large-Scale Multi-Document Summarization Dataset from the Wikipedia Current Events Portal|https://www.aclweb.org/anthology/2020.acl-main.120/|
|Timeline æ€»ç»“|Examining the State-of-the-Art in News Timeline Summarization|https://www.aclweb.org/anthology/2020.acl-main.122/|

## å…³é”®è¯æŠ½å–

|Title|Link|
|:---|:---|
|Exclusive Hierarchical Decoding for Deep Keyphrase Generation|https://www.aclweb.org/anthology/2020.acl-main.103/|
|Keyphrase Generation for Scientific Document Retrieval|https://www.aclweb.org/anthology/2020.acl-main.105/|
|
